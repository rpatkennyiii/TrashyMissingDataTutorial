{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Bayesian Imputation for Missing Values in Discrete Covariates\n","\n"," Missing data is a very widespread problem in practical applications, both in covariates ('explanatory variables') and outcomes.\n"," When performing bayesian inference with MCMC, imputing discrete missing values is not possible using Hamiltonian Monte Carlo techniques.\n"," One way around this problem is to create a new model that enumerates the discrete variables and does inference over the new model, which, for a single discrete variable, is a mixture model. (see e.g. [Stan's user guide on Latent Discrete Parameters](https://mc-stan.org/docs/2_18/stan-users-guide/change-point-section.html))\n"," Enumerating the discrete latent sites requires some manual math work that can get tedious for complex models.\n"," Inference by automatic enumeration of discrete variables is implemented in numpyro and allows for a very convenient way of dealing with missing discrete data.\n"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["import numpyro\n","from jax import numpy as jnp, random, ops\n","from jax.scipy.special import expit\n","from numpyro import distributions as dist, sample\n","from numpyro.infer.mcmc import MCMC\n","from numpyro.infer.hmc import NUTS\n","from math import inf\n","from graphviz import Digraph\n","import pandas as pd\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"markdown","metadata":{},"source":[" create random seeds and set size of simulated dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["simkeys = random.split(random.PRNGKey(0), 10)\n","nsim = 5000\n","mcmc_key = random.PRNGKey(1)\n","mcmc_2_key = random.PRNGKey(1)"]},{"cell_type":"markdown","metadata":{},"source":[" First we will simulate data with correlated binary covariates. The assumption is that we wish to estimate parameter for some parametric model without bias (e.g. for inferring a causal effect). For several different missing data patterns we will see how to impute the values to lead to unbiased models.\n","\n"," The basic data structure is as follows. Z is a latent variable that gives rise to the marginal dependence between A and B, the observed covariates. We will consider different missing data mechanisms for variable A, where variable B and Y are fully observed. The effects of A and B on Y are the effects of interest."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Pages: 1 -->\n<svg width=\"134pt\" height=\"188pt\"\n viewBox=\"0.00 0.00 134.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 130,-184 130,4 -4,4\"/>\n<!-- A -->\n<g id=\"node1\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- Y -->\n<g id=\"node4\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- A&#45;&gt;Y -->\n<g id=\"edge3\" class=\"edge\">\n<title>A&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n</g>\n<!-- B -->\n<g id=\"node2\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- B&#45;&gt;Y -->\n<g id=\"edge4\" class=\"edge\">\n<title>B&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n</g>\n<!-- Z -->\n<g id=\"node3\" class=\"node\">\n<title>Z</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n</g>\n<!-- Z&#45;&gt;A -->\n<g id=\"edge1\" class=\"edge\">\n<title>Z&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.65,-144.76C50.29,-136.28 44.85,-125.71 39.96,-116.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-114.44 35.3,-107.15 36.77,-117.64 42.99,-114.44\"/>\n</g>\n<!-- Z&#45;&gt;B -->\n<g id=\"edge2\" class=\"edge\">\n<title>Z&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.35,-144.76C75.71,-136.28 81.15,-125.71 86.04,-116.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.23,-117.64 90.7,-107.15 83.01,-114.44 89.23,-117.64\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x205f0ec0bb0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dot = Digraph()\n","dot.node(\"A\")\n","dot.node(\"B\")\n","dot.node(\"Z\")\n","dot.node(\"Y\")\n","dot.edges([\"ZA\", \"ZB\", \"AY\", \"BY\"])\n","dot"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["b_A = 0.25\n","b_B = 0.25\n","s_Y = 0.25\n","# Generate a random number\n","Z = random.normal(simkeys[0], (nsim,))\n","# Expit uses a sigmoid function to create a weight of the coin, which replaces p = 0.5 in the original documentation\n","A = random.bernoulli(key = simkeys[1], p = expit(Z))\n","B = random.bernoulli(key = simkeys[2], p = expit(Z))\n","# Create the Y variable that's made up of A, B, and variance Y \n","Y = A * b_A + B * b_B + s_Y * random.normal(simkeys[3], (nsim,))"]},{"cell_type":"markdown","metadata":{},"source":[" # MCAR"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["A_isobs_mcar = random.bernoulli(simkeys[4], jnp.ones(A.shape)*0.8)\n","Aobs_mcar = jnp.where(A_isobs_mcar, A, -1)\n","A_obsidx_mcar = jnp.where(A_isobs_mcar)\n","\n","# generate complete case arrays\n","Acc_mcar = Aobs_mcar[A_obsidx_mcar]\n","Bcc_mcar = B[A_obsidx_mcar]\n","Ycc_mcar = Y[A_obsidx_mcar]"]},{"cell_type":"markdown","metadata":{},"source":[" ### Complete Case Model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def ccmodel(A, B, Y):\n","    ntotal = A.shape[0]\n","    # get parameters of outcome model\n","    b_A = sample(\"b_A\", dist.Normal(0, 2.5))\n","    b_B = sample(\"b_B\", dist.Normal(0, 2.5))\n","    s_Y = sample(\"s_Y\", dist.HalfCauchy(2.5))\n","\n","    with numpyro.plate(\"obs\", ntotal):\n","        ### outcome model\n","        eta_Y = b_A * A + b_B * B\n","        sample(\"obs_Y\", dist.Normal(eta_Y, s_Y), obs=Y)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:06<00:00, 144.65it/s, 7 steps of size 4.52e-01. acc. prob=0.92]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.25      0.01      0.25      0.24      0.26    557.18      1.00\n","       b_B      0.25      0.01      0.25      0.24      0.26    487.23      1.00\n","       s_Y      0.25      0.00      0.25      0.25      0.26    428.99      1.00\n","\n","Number of divergences: 0\n"]}],"source":["cckernel = NUTS(ccmodel)\n","ccmcmc = MCMC(cckernel, num_warmup=250, num_samples=750)\n","ccmcmc.run(mcmc_key, Acc_mcar, Bcc_mcar, Ycc_mcar)\n","ccmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" ### Implicit Missingness Model with imputation from B"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def impmodel(A, B, Y):\n","    ntotal = A.shape[0]\n","    A_isobs = A >= 0\n","\n","    # get parameters of imputation model\n","    mu_A = sample(\"mu_A\", dist.Normal(0, 2.5))\n","    b_B_A = sample(\"b_B_A\", dist.Normal(0, 2.5))\n","\n","    # get parameters of outcome model\n","    b_A = sample(\"b_A\", dist.Normal(0, 2.5))\n","    b_B = sample(\"b_B\", dist.Normal(0, 2.5))\n","    s_Y = sample(\"s_Y\", dist.HalfCauchy(2.5))\n","\n","    with numpyro.plate(\"obs\", ntotal):\n","        ### imputation model\n","        # get linear predictor for missing values\n","        eta_A = mu_A + B * b_B_A\n","\n","        # sample imputation values for A\n","        # mask out to not add log_prob to total likelihood right now\n","        Aimp = sample(\n","            \"A\",\n","            dist.Bernoulli(logits=eta_A).mask(False),\n","            infer={\"enumerate\": \"parallel\"},\n","        )\n","\n","        # 'manually' calculate the log_prob\n","        log_prob = dist.Bernoulli(logits=eta_A).log_prob(Aimp)\n","\n","        # cancel out enumerated values that are not equal to observed values\n","        log_prob = jnp.where(A_isobs & (Aimp != A), -inf, log_prob)\n","\n","        # add to total likelihood for sampler\n","        numpyro.factor(\"A_obs\", log_prob)\n","\n","        ### outcome model\n","        eta_Y = b_A * Aimp + b_B * B\n","        sample(\"obs_Y\", dist.Normal(eta_Y, s_Y), obs=Y)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:09<00:00, 107.44it/s, 7 steps of size 4.93e-01. acc. prob=0.89]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.25      0.01      0.25      0.24      0.26    822.70      1.00\n","       b_B      0.25      0.01      0.25      0.24      0.26    705.92      1.00\n","     b_B_A      0.70      0.06      0.70      0.61      0.81    402.47      1.00\n","      mu_A     -0.34      0.04     -0.34     -0.41     -0.27    326.23      1.00\n","       s_Y      0.25      0.00      0.25      0.25      0.26    816.20      1.00\n","\n","Number of divergences: 0\n"]}],"source":["impkernel = NUTS(impmodel)\n","impmcmc = MCMC(impkernel, num_warmup=250, num_samples=750)\n","impmcmc.run(mcmc_key, Aobs_mcar, B, Y)\n","impmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" # MAR\n","\n"," ## MAR conditional on outcome\n","\n"," According to Rubin's classic definitions there are 3 distinct missing data mechanisms:\n","\n"," 1. missing completely at random (MCAR)\n"," 2. missing at random, conditional on observed data (MAR)\n"," 3. missing not at random, even after conditioning on observed data (MNAR)\n","\n"," Missing data mechanisms 1. and 2. are 'easy' to handle as they depend on observed data only.\n"," Mechanism 3. (MNAR) is trickier as it depends on data that is not observed, but may still be relevant to the outcome you are modeling (see below for a concrete example).\n","\n"," First we will generate missing values in A, conditional on the value of Y (thus it is a MAR mechanism)."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Pages: 1 -->\n<svg width=\"165pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 164.55 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 160.55,-256 160.55,4 -4,4\"/>\n<!-- Y -->\n<g id=\"node1\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- M -->\n<g id=\"node2\" class=\"node\">\n<title>M</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">M</text>\n</g>\n<!-- Y&#45;&gt;M -->\n<g id=\"edge1\" class=\"edge\">\n<title>Y&#45;&gt;M</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-90C56.61,-90 59.23,-90 61.84,-90\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61.93,-93.5 71.93,-90 61.93,-86.5 61.93,-93.5\"/>\n</g>\n<!-- Aobs -->\n<g id=\"node6\" class=\"node\">\n<title>Aobs</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"126\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"126\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Aobs</text>\n</g>\n<!-- M&#45;&gt;Aobs -->\n<g id=\"edge6\" class=\"edge\">\n<title>M&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M105.4,-72.41C108.51,-64.34 112.33,-54.43 115.83,-45.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.13,-46.55 119.46,-35.96 112.6,-44.03 119.13,-46.55\"/>\n</g>\n<!-- A -->\n<g id=\"node3\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- A&#45;&gt;Y -->\n<g id=\"edge4\" class=\"edge\">\n<title>A&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.43,-146.83C74.25,-136.94 60.48,-123.55 48.97,-112.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"51.41,-109.85 41.8,-105.38 46.53,-114.87 51.41,-109.85\"/>\n</g>\n<!-- A&#45;&gt;Aobs -->\n<g id=\"edge7\" class=\"edge\">\n<title>A&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112.75,-146.07C120.96,-136.1 130.62,-122.25 135,-108 141.26,-87.65 138.23,-63.57 134.07,-45.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"137.43,-44.6 131.55,-35.79 130.65,-46.35 137.43,-44.6\"/>\n</g>\n<!-- B -->\n<g id=\"node4\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- B&#45;&gt;Y -->\n<g id=\"edge5\" class=\"edge\">\n<title>B&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-143.7C27,-135.98 27,-126.71 27,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1\"/>\n</g>\n<!-- Z -->\n<g id=\"node5\" class=\"node\">\n<title>Z</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n</g>\n<!-- Z&#45;&gt;A -->\n<g id=\"edge2\" class=\"edge\">\n<title>Z&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.35,-216.76C75.71,-208.28 81.15,-197.71 86.04,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.23,-189.64 90.7,-179.15 83.01,-186.44 89.23,-189.64\"/>\n</g>\n<!-- Z&#45;&gt;B -->\n<g id=\"edge3\" class=\"edge\">\n<title>Z&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.65,-216.76C50.29,-208.28 44.85,-197.71 39.96,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-186.44 35.3,-179.15 36.77,-189.64 42.99,-186.44\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x205f90dca90>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["dot_mnar_y = Digraph()\n","with dot_mnar_y.subgraph() as s:\n","    s.attr(rank=\"same\")\n","    s.node(\"Y\")\n","    s.node(\"M\")\n","dot_mnar_y.node(\"A\")\n","dot_mnar_y.node(\"B\")\n","dot_mnar_y.node(\"Z\")\n","dot_mnar_y.node(\"M\")\n","dot_mnar_y.node('Aobs')\n","dot_mnar_y.edges([\"YM\", \"ZA\", \"ZB\", \"AY\", \"BY\",('M','Aobs'),('A','Aobs')])\n","dot_mnar_y"]},{"cell_type":"markdown","metadata":{},"source":[" This graph depicts the data generating mechanism, where Y is the only cause of missingness in A, denoted M. This means that the missingness in M is random, conditional on Y.\n","\n"," As an example consider this simplified scenario:\n","\n"," - A represents a history of heart illness\n"," - B represents the age of a patient\n"," - Y represents whether or not the patient will visit the general practitioner\n","\n"," A general practitioner wants to find out why patients that are assigned to her clinic will visit the clinic or not. She thinks that having a history of heart illness and age are potential causes of doctor visits. Data on patient ages are available through their registration forms, but information on prior heart illness may be available only after they have visited the clinic. This makes the missingness in A (history of heart disease), dependent on the outcome (visiting the clinic)."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["A_isobs = random.bernoulli(simkeys[4], expit(3 * (Y - Y.mean())))\n","Aobs = jnp.where(A_isobs, A, -1)\n","A_obsidx = jnp.where(A_isobs)\n","\n","# generate complete case arrays\n","Acc = Aobs[A_obsidx]\n","Bcc = B[A_obsidx]\n","Ycc = Y[A_obsidx]"]},{"cell_type":"markdown","metadata":{},"source":[" We will evaluate 2 approaches:\n","\n"," 1. complete case analysis (which will lead to biased inferences)\n"," 2. with imputation (conditional on B)\n","\n"," Note that explicitly including Y in the imputation model for A is unneccesary.\n"," The sampled imputations for A will condition on Y indirectly as the likelihood of Y is conditional on A.\n"," So values of A that give high likelihood to Y will be sampled more often than other values."]},{"cell_type":"markdown","metadata":{},"source":[" ### Complete Case Model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def ccmodel(A, B, Y):\n","    ntotal = A.shape[0]\n","    # get parameters of outcome model\n","    b_A = sample(\"b_A\", dist.Normal(0, 2.5))\n","    b_B = sample(\"b_B\", dist.Normal(0, 2.5))\n","    s_Y = sample(\"s_Y\", dist.HalfCauchy(2.5))\n","\n","    with numpyro.plate(\"obs\", ntotal):\n","        ### outcome model\n","        eta_Y = b_A * A + b_B * B\n","        sample(\"obs_Y\", dist.Normal(eta_Y, s_Y), obs=Y)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:05<00:00, 172.50it/s, 7 steps of size 4.96e-01. acc. prob=0.91]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.30      0.01      0.30      0.28      0.31    492.84      1.02\n","       b_B      0.28      0.01      0.28      0.27      0.29    445.01      1.01\n","       s_Y      0.25      0.00      0.25      0.24      0.25    390.18      1.00\n","\n","Number of divergences: 0\n"]}],"source":["cckernel = NUTS(ccmodel)\n","ccmcmc = MCMC(cckernel, num_warmup=250, num_samples=750)\n","ccmcmc.run(mcmc_key, Acc, Bcc, Ycc)\n","ccmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" ### Imputation Model\n","all A are imputed conditioned on the value of B"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:08<00:00, 113.95it/s, 7 steps of size 4.29e-01. acc. prob=0.92]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.25      0.01      0.25      0.24      0.26    536.77      1.01\n","       b_B      0.25      0.01      0.25      0.24      0.26    552.32      1.00\n","     b_B_A      0.75      0.08      0.75      0.64      0.89    239.20      1.00\n","      mu_A     -0.39      0.06     -0.40     -0.48     -0.30    238.77      1.00\n","       s_Y      0.25      0.00      0.25      0.25      0.26    750.67      1.00\n","\n","Number of divergences: 0\n"]}],"source":["impkernel = NUTS(impmodel)\n","impmcmc = MCMC(impkernel, num_warmup=250, num_samples=750)\n","impmcmc.run(mcmc_key, Aobs, B, Y)\n","impmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" As we can see, when data are missing conditionally on Y, imputation leads to consistent estimation of the parameter of interest (b_A and b_B)."]},{"cell_type":"markdown","metadata":{},"source":[" ## MAR conditional on Covariate B\n","for additional testing, lets make the missingness in A conditional on B"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Pages: 1 -->\n<svg width=\"162pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 162.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 158,-256 158,4 -4,4\"/>\n<!-- Y -->\n<g id=\"node1\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- M -->\n<g id=\"node2\" class=\"node\">\n<title>M</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"127\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">M</text>\n</g>\n<!-- Aobs -->\n<g id=\"node6\" class=\"node\">\n<title>Aobs</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Aobs</text>\n</g>\n<!-- M&#45;&gt;Aobs -->\n<g id=\"edge6\" class=\"edge\">\n<title>M&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M113.43,-74.15C104.89,-64.82 93.7,-52.57 84.03,-42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"86.33,-39.33 77,-34.31 81.16,-44.05 86.33,-39.33\"/>\n</g>\n<!-- A -->\n<g id=\"node3\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- A&#45;&gt;Y -->\n<g id=\"edge4\" class=\"edge\">\n<title>A&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.64,-144.41C36.91,-136.22 40.94,-126.14 44.62,-116.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"47.95,-118.05 48.41,-107.47 41.45,-115.45 47.95,-118.05\"/>\n</g>\n<!-- A&#45;&gt;Aobs -->\n<g id=\"edge7\" class=\"edge\">\n<title>A&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M21.39,-144.38C16.14,-126.09 10.31,-96.08 19,-72 23.21,-60.34 31.22,-49.44 39.27,-40.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"41.81,-42.99 46.25,-33.37 36.78,-38.12 41.81,-42.99\"/>\n</g>\n<!-- B -->\n<g id=\"node4\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- B&#45;&gt;Y -->\n<g id=\"edge5\" class=\"edge\">\n<title>B&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.02,-145.12C83.5,-136.34 76.54,-125.26 70.35,-115.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"73.23,-113.42 64.94,-106.82 67.3,-117.15 73.23,-113.42\"/>\n</g>\n<!-- B&#45;&gt;M -->\n<g id=\"edge1\" class=\"edge\">\n<title>B&#45;&gt;M</title>\n<path fill=\"none\" stroke=\"black\" d=\"M105.64,-144.41C108.91,-136.22 112.94,-126.14 116.62,-116.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.95,-118.05 120.41,-107.47 113.45,-115.45 119.95,-118.05\"/>\n</g>\n<!-- Z -->\n<g id=\"node5\" class=\"node\">\n<title>Z</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n</g>\n<!-- Z&#45;&gt;A -->\n<g id=\"edge2\" class=\"edge\">\n<title>Z&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.65,-216.76C50.29,-208.28 44.85,-197.71 39.96,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-186.44 35.3,-179.15 36.77,-189.64 42.99,-186.44\"/>\n</g>\n<!-- Z&#45;&gt;B -->\n<g id=\"edge3\" class=\"edge\">\n<title>Z&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.35,-216.76C75.71,-208.28 81.15,-197.71 86.04,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.23,-189.64 90.7,-179.15 83.01,-186.44 89.23,-189.64\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x205fc76efd0>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["dot_mnar_y = Digraph()\n","with dot_mnar_y.subgraph() as s:\n","    s.attr(rank=\"same\")\n","    s.node(\"Y\")\n","    s.node(\"M\")\n","dot_mnar_y.node(\"A\")\n","dot_mnar_y.node(\"B\")\n","dot_mnar_y.node(\"Z\")\n","dot_mnar_y.node(\"M\")\n","dot_mnar_y.node(\"Aobs\")\n","dot_mnar_y.edges([\"BM\", \"ZA\", \"ZB\", \"AY\", \"BY\",(\"M\",\"Aobs\"),(\"A\",\"Aobs\")])\n","dot_mnar_y"]},{"cell_type":"markdown","metadata":{},"source":[" ### Missingness Conditioned on B Setup\n"," here the missingness mask depends on B. If B is 1 there is a .2 chance of being observered, if B is 0 there is a .9 chance of A being observered."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["A_isobs_condB = random.bernoulli(simkeys[5], 0.9 - 0.8 * B)\n","Aobs_condB = jnp.where(A_isobs_condB, A, -1)\n","A_obsidx_condB = jnp.where(Aobs_condB)"]},{"cell_type":"markdown","metadata":{},"source":["calculated missingness fraction for missingness conditional on B"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["DeviceArray(0.4978, dtype=float32)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["jnp.mean(A_isobs_condB)"]},{"cell_type":"markdown","metadata":{},"source":["generate complete case arrays, all rows with any missind data are dropped"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["Acc_cond = Aobs_condB[A_obsidx_condB]\n","Bcc_cond = B[A_obsidx_condB]\n","Ycc_cond = Y[A_obsidx_condB]"]},{"cell_type":"markdown","metadata":{},"source":[" ### Complete Case Model"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:04<00:00, 206.86it/s, 7 steps of size 3.64e-01. acc. prob=0.93]"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.14      0.01      0.14      0.13      0.15    450.67      1.00\n","       b_B      0.53      0.01      0.53      0.51      0.54    456.38      1.00\n","       s_Y      0.29      0.00      0.29      0.28      0.29    240.35      1.00\n","\n","Number of divergences: 0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["cckernel = NUTS(ccmodel)\n","ccmcmc = MCMC(cckernel, num_warmup=250, num_samples=750)\n","ccmcmc.run(mcmc_key, Acc_cond, Bcc_cond, Ycc_cond)\n","ccmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" ### Implicit Missingness Model\n"," Here since since no missing model is specified, the imputation method implies that MAR missingness"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:07<00:00, 129.50it/s, 7 steps of size 3.97e-01. acc. prob=0.92]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.25      0.01      0.25      0.24      0.26    851.93      1.00\n","       b_B      0.25      0.01      0.25      0.24      0.27    458.70      1.00\n","     b_B_A      0.64      0.12      0.64      0.43      0.83    297.26      1.00\n","      mu_A     -0.36      0.04     -0.36     -0.42     -0.29    492.23      1.00\n","       s_Y      0.25      0.00      0.25      0.25      0.25    742.92      1.00\n","\n","Number of divergences: 0\n"]}],"source":["impkernel = NUTS(impmodel)\n","impmcmc = MCMC(impkernel, num_warmup=250, num_samples=750)\n","impmcmc.run(mcmc_key, Aobs_condB, B, Y)\n","impmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" # MNAR\n"," ## MNAR conditional on covariate\n","\n"," When data are missing conditional on unobserved data, things get more tricky.\n"," Here we will generate missing values in A, conditional on the value of A itself (missing not at random (MNAR), but missing at random conditional on A).\n","\n"," As an example consider patients who have cancer:\n","\n"," - A represents weight loss\n"," - B represents age\n"," - Y represents overall survival time\n","\n"," Both A and B can be related to survival time in cancer patients. For patients who have extreme weight loss, it is more likely that this will be noted by the doctor and registered in the electronic health record. For patients with no weight loss or little weight loss, it may be that the doctor forgets to ask about it and therefore does not register it in the records."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Pages: 1 -->\n<svg width=\"184pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 184.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 180,-256 180,4 -4,4\"/>\n<!-- B -->\n<g id=\"node1\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- Y -->\n<g id=\"node3\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"35\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"35\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- B&#45;&gt;Y -->\n<g id=\"edge5\" class=\"edge\">\n<title>B&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M28.98,-143.7C29.86,-135.98 30.92,-126.71 31.9,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"35.39,-118.44 33.05,-108.1 28.43,-117.64 35.39,-118.44\"/>\n</g>\n<!-- Z -->\n<g id=\"node2\" class=\"node\">\n<title>Z</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n</g>\n<!-- Z&#45;&gt;B -->\n<g id=\"edge3\" class=\"edge\">\n<title>Z&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54.65,-216.76C50.29,-208.28 44.85,-197.71 39.96,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-186.44 35.3,-179.15 36.77,-189.64 42.99,-186.44\"/>\n</g>\n<!-- A -->\n<g id=\"node5\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- Z&#45;&gt;A -->\n<g id=\"edge2\" class=\"edge\">\n<title>Z&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.35,-216.76C75.71,-208.28 81.15,-197.71 86.04,-188.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.23,-189.64 90.7,-179.15 83.01,-186.44 89.23,-189.64\"/>\n</g>\n<!-- Aobs -->\n<g id=\"node4\" class=\"node\">\n<title>Aobs</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"121\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Aobs</text>\n</g>\n<!-- A&#45;&gt;Y -->\n<g id=\"edge4\" class=\"edge\">\n<title>A&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M85.43,-146.15C76.69,-136.6 65.17,-123.99 55.34,-113.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"57.88,-110.84 48.55,-105.82 52.72,-115.57 57.88,-110.84\"/>\n</g>\n<!-- A&#45;&gt;Aobs -->\n<g id=\"edge7\" class=\"edge\">\n<title>A&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M101.65,-143.87C105.4,-119.67 112.29,-75.21 116.76,-46.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"120.26,-46.61 118.34,-36.19 113.35,-45.54 120.26,-46.61\"/>\n</g>\n<!-- M -->\n<g id=\"node6\" class=\"node\">\n<title>M</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">M</text>\n</g>\n<!-- A&#45;&gt;M -->\n<g id=\"edge1\" class=\"edge\">\n<title>A&#45;&gt;M</title>\n<path fill=\"none\" stroke=\"black\" d=\"M110.1,-145.46C116.51,-136.49 124.7,-125.02 131.92,-114.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"134.97,-116.66 137.93,-106.49 129.27,-112.59 134.97,-116.66\"/>\n</g>\n<!-- M&#45;&gt;Aobs -->\n<g id=\"edge6\" class=\"edge\">\n<title>M&#45;&gt;Aobs</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.36,-72.41C139.13,-64.34 135.17,-54.43 131.54,-45.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"134.75,-43.94 127.78,-35.96 128.25,-46.54 134.75,-43.94\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x20581814be0>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["dot_mnar_x = Digraph()\n","with dot_mnar_y.subgraph() as s:\n","    s.attr(rank=\"same\")\n","    s.node(\"A\")\n","    s.node(\"M\")\n","dot_mnar_x.node(\"B\")\n","dot_mnar_x.node(\"Z\")\n","dot_mnar_x.node(\"Y\")\n","dot_mnar_x.node(\"Aobs\")\n","dot_mnar_x.edges([\"AM\", \"ZA\", \"ZB\", \"AY\", \"BY\",('M','Aobs'), ('A', 'Aobs')])\n","dot_mnar_x"]},{"cell_type":"markdown","metadata":{},"source":[" ### Missingness Conditioned on A Setup"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["A_isobs = random.bernoulli(simkeys[5], 0.9 - 0.8 * A)\n","Aobs = jnp.where(A_isobs, A, -1)\n","A_obsidx = jnp.where(A_isobs)"]},{"cell_type":"markdown","metadata":{},"source":["generate complete case arrays"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["Acc = Aobs[A_obsidx]\n","Bcc = B[A_obsidx]\n","Ycc = Y[A_obsidx]"]},{"cell_type":"markdown","metadata":{},"source":[" ### Run Complete Case Model on MNAR data"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:04<00:00, 239.63it/s, 7 steps of size 6.66e-01. acc. prob=0.91]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.27      0.02      0.27      0.24      0.29    653.07      1.00\n","       b_B      0.25      0.01      0.25      0.24      0.26    838.25      1.00\n","       s_Y      0.25      0.00      0.25      0.24      0.25    431.83      1.00\n","\n","Number of divergences: 0\n"]}],"source":["cckernel = NUTS(ccmodel)\n","ccmcmc = MCMC(cckernel, num_warmup=250, num_samples=750)\n","ccmcmc.run(mcmc_key, Acc, Bcc, Ycc)\n","ccmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" ### Run Implicit Missingness Model on MNAR data\n"," here MAR is assumed by not specifying a missingness model"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:06<00:00, 155.44it/s, 3 steps of size 5.72e-01. acc. prob=0.88]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.34      0.01      0.34      0.32      0.36    757.29      1.00\n","       b_B      0.33      0.01      0.33      0.32      0.34    808.49      1.00\n","     b_B_A      0.33      0.11      0.33      0.15      0.50    283.85      1.01\n","      mu_A     -1.82      0.08     -1.81     -1.96     -1.69    327.37      1.01\n","       s_Y      0.26      0.00      0.26      0.25      0.26    688.30      1.00\n","\n","Number of divergences: 0\n"]}],"source":["impkernel = NUTS(impmodel)\n","impmcmc = MCMC(impkernel, num_warmup=250, num_samples=750)\n","impmcmc.run(mcmc_key, Aobs, B, Y)\n","impmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" Perhaps surprisingly, imputing missing values when the missingness mechanism depends on the variable itself will actually lead to bias, while complete case analysis is unbiased!\n"," See e.g. [Bias and efficiency of multiple imputation compared with complete‐case analysis for missing covariate values](https://doi.org/10.1002/sim.3944).\n","\n"," However, complete case analysis may be undesirable as well. E.g. due to leading to lower precision in estimating the parameter from B to Y, or maybe when there is an expected difference interaction between the value of A and the parameter from A to Y. To deal with this situation, an explicit model for the reason of missingness (/observation) is required. We will add one below."]},{"cell_type":"markdown","metadata":{},"source":[" ### Run Explicit Missingness Model on MNAR and MAR data\n"," where the missingness mechinism is directly modeled and treated as fully MNAR"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["def impmissmodel(A, B, Y, mtype='MNAR', **kwargs):\n","    ntotal = A.shape[0]\n","    A_isobs = A >= 0\n","\n","    # get parameters of imputation model\n","    mu_A = sample(\"mu_A\", dist.Normal(0, 2.5), **kwargs)\n","    b_B_A = sample(\"b_B_A\", dist.Normal(0, 2.5), **kwargs)\n","\n","    # get parameters of outcome model\n","    b_A = sample(\"b_A\", dist.Normal(0, 2.5), **kwargs)\n","    b_B = sample(\"b_B\", dist.Normal(0, 2.5), **kwargs)\n","    s_Y = sample(\"s_Y\", dist.HalfCauchy(2.5), **kwargs)\n","\n","    # get parameter of model of missingness\n","    with numpyro.plate(\"obsmodel\", 2):\n","        p_Aobs = sample(\"p_Aobs\", dist.Beta(1, 1), **kwargs)\n","\n","    with numpyro.plate(\"obs\", ntotal):\n","        ### imputation model\n","        # get linear predictor for missing values\n","        eta_A = mu_A + B * b_B_A\n","        \n","        # sample imputation values for A\n","        # mask out to not add log_prob to total likelihood right now\n","        Aimp = sample(\n","            \"A\",\n","            dist.Bernoulli(logits=eta_A).mask(False),\n","            infer={\"enumerate\": \"parallel\"}, **kwargs\n","        )\n","\n","        # 'manually' calculate the log_prob\n","        log_prob = dist.Bernoulli(logits=eta_A).log_prob(Aimp)\n","\n","        # cancel out enumerated values that are not equal to observed values\n","        log_prob = jnp.where(A_isobs & (Aimp != A), -inf, log_prob)\n","\n","        # add to total likelihood for sampler\n","        numpyro.factor(\"obs_A\", log_prob)\n","\n","        ### outcome model\n","        eta_Y = b_A * Aimp + b_B * B\n","        sample(\"obs_Y\", dist.Normal(eta_Y, s_Y), obs=Y)\n","\n","        M = Aimp if mtype == 'MNAR' else B\n","        ### missingness / observation model\n","        eta_Aobs = jnp.where(M, p_Aobs[0], p_Aobs[1])"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:15<00:00, 66.28it/s, 7 steps of size 5.02e-01. acc. prob=0.89]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.34      0.01      0.34      0.32      0.36    921.42      1.00\n","       b_B      0.33      0.01      0.33      0.32      0.35   1071.01      1.00\n","     b_B_A      0.33      0.11      0.33      0.15      0.51    418.33      1.00\n","      mu_A     -1.82      0.08     -1.81     -1.96     -1.70    524.39      1.00\n"," p_Aobs[0]      0.49      0.29      0.51      0.00      0.89    929.51      1.00\n"," p_Aobs[1]      0.51      0.30      0.52      0.05      0.95    994.33      1.00\n","       s_Y      0.26      0.00      0.26      0.25      0.26    922.38      1.01\n","\n","Number of divergences: 0\n"]}],"source":["impmisskernel = NUTS(impmissmodel)\n","impmissmcmc = MCMC(impmisskernel, num_warmup=250, num_samples=750)\n","impmissmcmc.run(mcmc_key, Aobs, B, Y, mtype='MNAR', asdfasdf=5)\n","impmissmcmc.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" #### Correct Assumption on Missingness"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:13<00:00, 74.10it/s, 7 steps of size 3.79e-01. acc. prob=0.93] \n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.25      0.01      0.25      0.24      0.26    732.74      1.00\n","       b_B      0.25      0.01      0.25      0.24      0.27    497.55      1.00\n","     b_B_A      0.65      0.12      0.65      0.45      0.85    384.33      1.00\n","      mu_A     -0.36      0.04     -0.35     -0.42     -0.29    487.15      1.00\n"," p_Aobs[0]      0.51      0.29      0.51      0.11      1.00    777.55      1.00\n"," p_Aobs[1]      0.47      0.29      0.48      0.00      0.88    781.59      1.00\n","       s_Y      0.25      0.00      0.25      0.25      0.25    592.92      1.00\n","\n","Number of divergences: 0\n"]}],"source":["impmisskernel_condB = NUTS(impmissmodel)\n","impmcmc_condB = MCMC(impmisskernel, num_warmup=250, num_samples=750)\n","impmcmc_condB.run(mcmc_key, Aobs_condB, B, Y)\n","impmcmc_condB.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" #### Wrong Assumption about Missingness"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:16<00:00, 59.07it/s, 7 steps of size 5.02e-01. acc. prob=0.89]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.34      0.01      0.34      0.32      0.36    921.42      1.00\n","       b_B      0.33      0.01      0.33      0.32      0.35   1071.01      1.00\n","     b_B_A      0.33      0.11      0.33      0.15      0.51    418.33      1.00\n","      mu_A     -1.82      0.08     -1.81     -1.96     -1.70    524.39      1.00\n"," p_Aobs[0]      0.49      0.29      0.51      0.00      0.89    929.51      1.00\n"," p_Aobs[1]      0.51      0.30      0.52      0.05      0.95    994.33      1.00\n","       s_Y      0.26      0.00      0.26      0.25      0.26    922.38      1.01\n","\n","Number of divergences: 0\n"]}],"source":["# Implicit made Explicit \n","# The estmates are still biased, in exactly the same way when the model was implicit. \n","impmisskernel_condB = NUTS(impmissmodel)\n","impmcmc_condB = MCMC(impmisskernel, num_warmup=250, num_samples=750)\n","impmcmc_condB.run(mcmc_key, Aobs, B, Y, )\n","impmcmc_condB.print_summary()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:15<00:00, 65.71it/s, 7 steps of size 5.02e-01. acc. prob=0.89]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","       b_A      0.34      0.01      0.34      0.32      0.36    921.42      1.00\n","       b_B      0.33      0.01      0.33      0.32      0.35   1071.01      1.00\n","     b_B_A      0.33      0.11      0.33      0.15      0.51    418.33      1.00\n","      mu_A     -1.82      0.08     -1.81     -1.96     -1.70    524.39      1.00\n"," p_Aobs[0]      0.49      0.29      0.51      0.00      0.89    929.51      1.00\n"," p_Aobs[1]      0.51      0.30      0.52      0.05      0.95    994.33      1.00\n","       s_Y      0.26      0.00      0.26      0.25      0.26    922.38      1.01\n","\n","Number of divergences: 0\n"]}],"source":["# Implicit made Explicit \n","# The estmates are still biased, in exactly the same way when the model was implicit. \n","impmisskernel_condB = NUTS(impmissmodel)\n","impmcmc_condB = MCMC(impmisskernel, num_warmup=250, num_samples=750)\n","impmcmc_condB.run(mcmc_key, Aobs, B, Y, 'MAR')\n","impmcmc_condB.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":[" We can now estimate the parameters b_A and b_B without bias, while still utilizing all observations.\n"," Obviously, modeling the missingness mechanism **relies on assumptions** that need either be substantiated with prior evidence, or possibly analyzed through sensitivity analysis.\n","\n"," For more reading on missing data in bayesian inference, see:\n","\n"," - [Presentation Bayesian Methods for missing data (pdf)](https://www.bayes-pharma.org/Abstracts2013/slides/NickyBest_MissingData.pdf)\n"," - [Bayesian Approaches for Missing Not at\n"," Random Outcome Data: The Role of\n"," Identifying Restrictions (doi:10.1214/17-STS630)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6936760/)"]},{"cell_type":"markdown","metadata":{},"source":[" # Data Example"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["df = pd.read_csv('dataset.csv.zip').drop(columns='Unnamed: 83')"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["input_cols = ['ventilated_apache','apache_4a_hospital_death_prob']\n","input_zscore = ['d1_sysbp_min','d1_temp_min']\n","input_onehot = ['gcs_eyes_apache']\n","y_val = 'hospital_death'"]},{"cell_type":"markdown","metadata":{},"source":["sandardize continious varriables, one hot encode the catigorical, replace -1 with null where appropriate"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["df_list = [df[input_zscore].apply(lambda x: (x-x.mean())/x.std())\\\n","    .rename(columns=lambda x:x+'_zscore'), df[input_cols]\n","        , pd.get_dummies(df['gcs_eyes_apache']).rename(columns = lambda x: f'gcs_eyes_apache_{int(x)}')]"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["df_in = pd.concat(df_list, axis=1)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["df_in['apache_4a_hospital_death_prob'].replace(-1, jnp.nan, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":[" ## complete data example"]},{"cell_type":"markdown","metadata":{},"source":[" ### create complete data model"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def ccmodel_realdata_x(X, Y):\n","    ntotal = X.shape[0]\n","    # get parameters of outcome model\n","    b_X = sample(\"b_X\", dist.Normal(jnp.zeros(X.shape[1]+1),jnp.ones(X.shape[1]+1)*2.5))\n","    \n","    with numpyro.plate(\"obs\", ntotal):\n","        ### outcome model\n","        eta_Y = (b_X[1:]*X).sum(axis=1)+b_X[0]\n","        sample(\"obs_Y\", dist.Bernoulli(logits=eta_Y), obs=Y)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["df_real_comp = pd.concat([df_in, df[y_val]], axis = 1)\n","df_real_comp.dropna(inplace = True)\n","df_real_comp = df_real_comp[df_real_comp['apache_4a_hospital_death_prob']>=0]"]},{"cell_type":"markdown","metadata":{},"source":[" check fraction of rows lost to missingness"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["0.8660168133198128"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["df_real_comp.shape[0] / df_in.shape[0]"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["X_real_cc = jnp.array(df_real_comp.drop(columns=y_val))\n","Y_real_cc = jnp.array(df_real_comp[y_val])"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["sample: 100%|██████████| 1000/1000 [00:47<00:00, 20.85it/s, 31 steps of size 1.21e-01. acc. prob=0.93]\n"]},{"name":"stdout","output_type":"stream","text":["\n","                mean       std    median      5.0%     95.0%     n_eff     r_hat\n","    b_X[0]     -3.60      0.11     -3.59     -3.77     -3.43    139.52      1.00\n","    b_X[1]     -0.42      0.02     -0.42     -0.44     -0.39    680.54      1.00\n","    b_X[2]     -0.09      0.01     -0.09     -0.10     -0.07    721.32      1.00\n","    b_X[3]      0.38      0.04      0.38      0.31      0.43    403.70      1.00\n","    b_X[4]      5.48      0.08      5.48      5.34      5.61    465.68      1.00\n","    b_X[5]     -0.50      0.11     -0.50     -0.68     -0.33    150.96      1.01\n","    b_X[6]     -0.21      0.11     -0.20     -0.38     -0.02    156.98      1.00\n","    b_X[7]     -0.07      0.11     -0.08     -0.24      0.11    150.83      1.00\n","    b_X[8]     -0.07      0.11     -0.07     -0.23      0.10    139.25      1.00\n","\n","Number of divergences: 0\n"]}],"source":["ccmcmc_real_x = NUTS(ccmodel_realdata_x)\n","ccmcmc_real_x = MCMC(ccmcmc_real_x, num_warmup=250, num_samples=750)\n","ccmcmc_real_x.run(mcmc_key, X_real_cc, Y_real_cc)\n","ccmcmc_real_x.print_summary()"]},{"cell_type":"markdown","metadata":{},"source":["get coefficient samples. Many of the inputs come from the APACHE model used for accuity evaluation in ICUs, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5971641/. One of the inputs in the output of the model while the others are inputs. This likely explains why some of the features are seemingly protective, since they are already inplicitly included in the APACHE model output in the death prob column."]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["df_coefs = pd.DataFrame(ccmcmc_real_x.get_samples()['b_X'],columns = ['const']+list(df_in.columns))"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>const</th>\n","      <th>d1_sysbp_min_zscore</th>\n","      <th>d1_temp_min_zscore</th>\n","      <th>ventilated_apache</th>\n","      <th>apache_4a_hospital_death_prob</th>\n","      <th>gcs_eyes_apache_1</th>\n","      <th>gcs_eyes_apache_2</th>\n","      <th>gcs_eyes_apache_3</th>\n","      <th>gcs_eyes_apache_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","      <td>750.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-3.596361</td>\n","      <td>-0.418941</td>\n","      <td>-0.085513</td>\n","      <td>0.378223</td>\n","      <td>5.483343</td>\n","      <td>-0.497971</td>\n","      <td>-0.207232</td>\n","      <td>-0.073439</td>\n","      <td>-0.073443</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.108895</td>\n","      <td>0.016003</td>\n","      <td>0.010836</td>\n","      <td>0.036625</td>\n","      <td>0.084181</td>\n","      <td>0.107499</td>\n","      <td>0.113321</td>\n","      <td>0.107282</td>\n","      <td>0.106189</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-3.912349</td>\n","      <td>-0.466824</td>\n","      <td>-0.119222</td>\n","      <td>0.241544</td>\n","      <td>5.237609</td>\n","      <td>-0.821409</td>\n","      <td>-0.645463</td>\n","      <td>-0.431571</td>\n","      <td>-0.443115</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-3.669409</td>\n","      <td>-0.428748</td>\n","      <td>-0.092765</td>\n","      <td>0.356063</td>\n","      <td>5.421003</td>\n","      <td>-0.570890</td>\n","      <td>-0.288083</td>\n","      <td>-0.145551</td>\n","      <td>-0.144659</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-3.592384</td>\n","      <td>-0.419124</td>\n","      <td>-0.085847</td>\n","      <td>0.379572</td>\n","      <td>5.483545</td>\n","      <td>-0.502087</td>\n","      <td>-0.203098</td>\n","      <td>-0.080113</td>\n","      <td>-0.074981</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>-3.519486</td>\n","      <td>-0.408731</td>\n","      <td>-0.078943</td>\n","      <td>0.401514</td>\n","      <td>5.541597</td>\n","      <td>-0.422584</td>\n","      <td>-0.129835</td>\n","      <td>-0.002101</td>\n","      <td>-0.002186</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>-3.211138</td>\n","      <td>-0.369452</td>\n","      <td>-0.046891</td>\n","      <td>0.477815</td>\n","      <td>5.719167</td>\n","      <td>-0.207038</td>\n","      <td>0.155810</td>\n","      <td>0.242961</td>\n","      <td>0.252253</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            const  d1_sysbp_min_zscore  d1_temp_min_zscore  ventilated_apache  \\\n","count  750.000000           750.000000          750.000000         750.000000   \n","mean    -3.596361            -0.418941           -0.085513           0.378223   \n","std      0.108895             0.016003            0.010836           0.036625   \n","min     -3.912349            -0.466824           -0.119222           0.241544   \n","25%     -3.669409            -0.428748           -0.092765           0.356063   \n","50%     -3.592384            -0.419124           -0.085847           0.379572   \n","75%     -3.519486            -0.408731           -0.078943           0.401514   \n","max     -3.211138            -0.369452           -0.046891           0.477815   \n","\n","       apache_4a_hospital_death_prob  gcs_eyes_apache_1  gcs_eyes_apache_2  \\\n","count                     750.000000         750.000000         750.000000   \n","mean                        5.483343          -0.497971          -0.207232   \n","std                         0.084181           0.107499           0.113321   \n","min                         5.237609          -0.821409          -0.645463   \n","25%                         5.421003          -0.570890          -0.288083   \n","50%                         5.483545          -0.502087          -0.203098   \n","75%                         5.541597          -0.422584          -0.129835   \n","max                         5.719167          -0.207038           0.155810   \n","\n","       gcs_eyes_apache_3  gcs_eyes_apache_4  \n","count         750.000000         750.000000  \n","mean           -0.073439          -0.073443  \n","std             0.107282           0.106189  \n","min            -0.431571          -0.443115  \n","25%            -0.145551          -0.144659  \n","50%            -0.080113          -0.074981  \n","75%            -0.002101          -0.002186  \n","max             0.242961           0.252253  "]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["df_coefs.describe()"]},{"cell_type":"markdown","metadata":{},"source":["calculate training AUC"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["Y_real_shuffled = random.permutation(key = simkeys[6], x = Y_real_cc)\n","reg_comp = df_coefs.mean().values[0] + (df_coefs.mean().values[:-1]*df_real_comp.iloc[:,:-1]).sum(axis=1).values\n","reg_probs = 1/(1+jnp.exp(-reg_comp))"]},{"cell_type":"markdown","metadata":{},"source":["calculated train auc"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"data":{"text/plain":["0.7550046582262938"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["roc_auc_score(y_true =  Y_real_cc,\n","              y_score = reg_probs)"]},{"cell_type":"markdown","metadata":{},"source":["check that AUC is bad for random targets"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["0.4966132078321661"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["roc_auc_score(y_true =  Y_real_shuffled,\n","              y_score = reg_probs)"]},{"cell_type":"markdown","metadata":{},"source":[" ### create discrete imputation model for real data\n"," subset to just rows with complete continuous data and impute missing discrete data"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["Xcont_cols = [col for col in df_in.columns if 'gcs_eyes_apache' not in col]\n","Xdisc_cols = [col for col in df_in.columns if 'gcs_eyes_apache' in col]\n","Xcont_df = df_in[Xcont_cols].dropna()\n","\n","Xcont = jnp.array(Xcont_df.values)\n","Xdisc = jnp.array(df_in.loc[Xcont_df.index, Xdisc_cols].values)\n","\n","X_isobs = jnp.array(df_in.iloc[Xcont_df.index,-4:].max(axis=1).values)\n","X_obsidx = jnp.where(X_isobs)\n","\n","Y_imp = jnp.array(df[df.index.isin(Xcont_df.index)][y_val].values)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["# Earlyn: For testing things out\n","def impmissmodel_realdata_x(Xcont, Xdisc, Xisobs, Y):\n","    # Implement this: numpyro.util.format_shapes\n","    \n","    ntotal = Xcont.shape[0]\n","    # get parameters of outcome model\n","    b_X = sample(\"b_X\", dist.Normal(jnp.zeros(Xcont.shape[1]+Xdisc.shape[1]+1)\n","                                        , jnp.ones(Xcont.shape[1]+Xdisc.shape[1]+1)*2.5))\n","    mu_X = sample(\"mu_X\", dist.Normal(0, 2.5))\n","    b_Xcont_Ximp = sample(\"b_X_Ximp\", dist.Normal(jnp.zeros((Xcont.shape[1] * Xdisc.shape[1]))\n","                                                 ,jnp.ones((Xcont.shape[1] * Xdisc.shape[1]))*2.5))\n","\n","    with numpyro.plate(\"obs\", size = ntotal):\n","        b_Xcont_Ximp_reshaped = b_Xcont_Ximp.reshape((Xcont.shape[1] , Xdisc.shape[1]))\n","        eta_X = mu_X + jnp.matmul(Xcont, b_Xcont_Ximp_reshaped)\n","        # sample imputation values for A\n","        # mask out to not add log_prob to total likelihood right now\n","        Ximp = sample(\"X\", dist.Categorical(logits=eta_X).mask(False),\n","            infer={\"enumerate\": \"parallel\"})\n","        \n","        # 'manually' calculate the log_prob\n","        log_prob = dist.Categorical(logits=eta_X).log_prob(Ximp)\n","        \n","        # One hot encode the imputation \n","        Ximp_onehot = jnp.zeros((Ximp.size, Ximp.max() + 1))\n","        Ximp_onehot = Ximp_onehot.at[jnp.arange(Ximp.size), Ximp].set(1)  \n","\n","        # cancel out enumerated values that are not equal to observed values\n","        log_prob = jnp.where(Xisobs & (Ximp_onehot != Xdisc).min(axis = 1), -inf, log_prob)\n","\n","        # add to total likelihood for sampler\n","        numpyro.factor(\"obs_X\", log_prob)\n","        \n","        X_0 = jnp.ones((ntotal, 1))\n","        X_with_imp = jnp.concatenate([Xcont,Ximp_onehot], axis = 1)\n","        \n","        ### outcome model\n","        eta_Y = jnp.matmul(X_with_imp,b_X[1:])+b_X[0]\n","        sample(\"obs_Y\", dist.Bernoulli(logits=eta_Y), obs=Y)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Missing a plate statement for batch dimension -1 at site 'b_X'. You can use `numpyro.util.format_shapes` utility to check shapes at all sites of your model.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn [102], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m impmissmcmc_real_x_kernel \u001b[38;5;241m=\u001b[39m NUTS(impmissmodel_realdata_x)\n\u001b[0;32m      2\u001b[0m impmissmcmc_real_x \u001b[38;5;241m=\u001b[39m MCMC(impmissmcmc_real_x_kernel, num_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m750\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimpmissmcmc_real_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmcmc_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXcont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXdisc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_isobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_imp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m impmissmcmc_real_x\u001b[38;5;241m.\u001b[39mprint_summary()\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\infer\\mcmc.py:593\u001b[0m, in \u001b[0;36mMCMC.run\u001b[1;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m map_args \u001b[39m=\u001b[39m (rng_key, init_state, init_params)\n\u001b[0;32m    592\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_chains \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 593\u001b[0m     states_flat, last_state \u001b[39m=\u001b[39m partial_map_fn(map_args)\n\u001b[0;32m    594\u001b[0m     states \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[jnp\u001b[39m.\u001b[39mnewaxis, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], states_flat)\n\u001b[0;32m    595\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\infer\\mcmc.py:381\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[1;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[0;32m    379\u001b[0m rng_key, init_state, init_params \u001b[39m=\u001b[39m init\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m init_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     init_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler\u001b[39m.\u001b[39;49minit(\n\u001b[0;32m    382\u001b[0m         rng_key,\n\u001b[0;32m    383\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_warmup,\n\u001b[0;32m    384\u001b[0m         init_params,\n\u001b[0;32m    385\u001b[0m         model_args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    386\u001b[0m         model_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m    387\u001b[0m     )\n\u001b[0;32m    388\u001b[0m sample_fn, postprocess_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cached_fns()\n\u001b[0;32m    389\u001b[0m diagnostics \u001b[39m=\u001b[39m (\n\u001b[0;32m    390\u001b[0m     \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler\u001b[39m.\u001b[39mget_diagnostics_str(x[\u001b[39m0\u001b[39m])\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m rng_key\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    392\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m )  \u001b[39m# noqa: E731\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\infer\\hmc.py:706\u001b[0m, in \u001b[0;36mHMC.init\u001b[1;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39m# vectorized\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     rng_key, rng_key_init_model \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mswapaxes(\n\u001b[0;32m    704\u001b[0m         vmap(random\u001b[39m.\u001b[39msplit)(rng_key), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[0;32m    705\u001b[0m     )\n\u001b[1;32m--> 706\u001b[0m init_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_state(\n\u001b[0;32m    707\u001b[0m     rng_key_init_model, model_args, model_kwargs, init_params\n\u001b[0;32m    708\u001b[0m )\n\u001b[0;32m    709\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_potential_fn \u001b[39mand\u001b[39;00m init_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    711\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mValid value of `init_params` must be provided with\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m `potential_fn`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    712\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\infer\\hmc.py:652\u001b[0m, in \u001b[0;36mHMC._init_state\u001b[1;34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init_state\u001b[39m(\u001b[39mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[0;32m    651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 652\u001b[0m         init_params, potential_fn, postprocess_fn, model_trace \u001b[39m=\u001b[39m initialize_model(\n\u001b[0;32m    653\u001b[0m             rng_key,\n\u001b[0;32m    654\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model,\n\u001b[0;32m    655\u001b[0m             dynamic_args\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    656\u001b[0m             init_strategy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_strategy,\n\u001b[0;32m    657\u001b[0m             model_args\u001b[39m=\u001b[39;49mmodel_args,\n\u001b[0;32m    658\u001b[0m             model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[0;32m    659\u001b[0m             forward_mode_differentiation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_mode_differentiation,\n\u001b[0;32m    660\u001b[0m         )\n\u001b[0;32m    661\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    662\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_fn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_fn \u001b[39m=\u001b[39m hmc(\n\u001b[0;32m    663\u001b[0m                 potential_fn_gen\u001b[39m=\u001b[39mpotential_fn,\n\u001b[0;32m    664\u001b[0m                 kinetic_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kinetic_fn,\n\u001b[0;32m    665\u001b[0m                 algo\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_algo,\n\u001b[0;32m    666\u001b[0m             )\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\infer\\util.py:630\u001b[0m, in \u001b[0;36minitialize_model\u001b[1;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, enum):\n\u001b[0;32m    629\u001b[0m         max_plate_nesting \u001b[39m=\u001b[39m _guess_max_plate_nesting(model_trace)\n\u001b[1;32m--> 630\u001b[0m         _validate_model(model_trace, plate_warning\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    631\u001b[0m         model \u001b[39m=\u001b[39m enum(config_enumerate(model), \u001b[39m-\u001b[39mmax_plate_nesting \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Pat.Kenny\\.virtualenvs\\TrashyMissingDataTutorial-MOYeDxqq\\lib\\site-packages\\numpyro\\util.py:542\u001b[0m, in \u001b[0;36m_validate_model\u001b[1;34m(model_trace, plate_warning)\u001b[0m\n\u001b[0;32m    535\u001b[0m message \u001b[39m=\u001b[39m (\n\u001b[0;32m    536\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing a plate statement for batch dimension \u001b[39m\u001b[39m{\u001b[39;00mdim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m at site \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You can use `numpyro.util.format_shapes`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m utility to check shapes at all sites of your model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m )\n\u001b[0;32m    541\u001b[0m \u001b[39mif\u001b[39;00m plate_warning \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n\u001b[0;32m    543\u001b[0m \u001b[39melif\u001b[39;00m plate_warning \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (\u001b[39mlen\u001b[39m(plate_dims) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    544\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, stacklevel\u001b[39m=\u001b[39mfind_stack_level())\n","\u001b[1;31mValueError\u001b[0m: Missing a plate statement for batch dimension -1 at site 'b_X'. You can use `numpyro.util.format_shapes` utility to check shapes at all sites of your model."]}],"source":["impmissmcmc_real_x_kernel = NUTS(impmissmodel_realdata_x)\n","impmissmcmc_real_x = MCMC(impmissmcmc_real_x_kernel, num_warmup=250, num_samples=750)\n","impmissmcmc_real_x.run(mcmc_key, Xcont, Xdisc, X_isobs, Y_imp)\n","impmissmcmc_real_x.print_summary()"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"data":{"text/plain":["<function __main__.impmissmodel_realdata_x(Xcont, Xdisc, Xisobs, Y)>"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["impmissmodel_realdata_x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 ('TrashyMissingDataTutorial-MOYeDxqq')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9865b1c43343a189b53a4d62656d98cf9623814172f5e175f4aab28a9d6264dd"}}},"nbformat":4,"nbformat_minor":2}
